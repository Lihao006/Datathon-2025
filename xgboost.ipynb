{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f88be3",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476a2f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import dalex as dx\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import shap\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from alibi.explainers import Counterfactual\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f8063",
   "metadata": {},
   "source": [
    "# 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866633f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "df_train = pd.read_csv('./dataset.csv')\n",
    "X_train_full = df_train.iloc[:,1:].drop('target_variable', axis=1)\n",
    "\n",
    "y_train_full = df_train['target_variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d226b00a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Split into train and test sets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m(\n\u001b[32m      3\u001b[39m     X_train_full,\n\u001b[32m      4\u001b[39m     y_train_full,\n\u001b[32m      5\u001b[39m     test_size=\u001b[32m0.2\u001b[39m,\n\u001b[32m      6\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m      7\u001b[39m     stratify=y_train_full\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1e2569",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430d312",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instance\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0573ff41",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a057b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ec2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac5a382",
   "metadata": {},
   "source": [
    "### Buscando los mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfed218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo base\n",
    "bst = XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "# Espacio de búsqueda\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Búsqueda aleatoria (más rápida que GridSearch)\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=bst,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Número de combinaciones a probar\n",
    "    scoring='f1',  # Optimizar F1-score\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo\n",
    "best_bst = search.best_estimator_\n",
    "print(\"Mejores parámetros:\", search.best_params_)\n",
    "\n",
    "\n",
    "# Mejores parámetros: {'subsample': 0.9, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c220bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instance\n",
    "best_bst = XGBClassifier(subsample=0.9, n_estimators=300, min_child_weight=1, max_depth=9, learning_rate=0.1, colsample_bytree=0.9, objective='binary:logistic')\n",
    "\n",
    "# fit model\n",
    "best_bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "preds = best_bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e45bb",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a8d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir con el mejor modelo\n",
    "preds_best = best_bst.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "print(classification_report(y_test, preds_best))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm_best = confusion_matrix(y_test, preds_best)\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de confusión - Mejor modelo')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4db89",
   "metadata": {},
   "source": [
    "### Métodos locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65564ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot (recomendado en SHAP moderno)\n",
    "# Solo la primera instancia\n",
    "explanation = explainer(X_test.iloc[:1])  \n",
    "shap.waterfall_plot(explanation[0], max_display=len(X_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506a435",
   "metadata": {},
   "source": [
    "#### Sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el explainer SHAP para XGBoost\n",
    "explainer = shap.TreeExplainer(best_bst)\n",
    "\n",
    "# Obtener SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Si es clasificación binaria, XGBoost devuelve una lista de arrays\n",
    "# shap_values[0] = clase 0, shap_values[1] = clase 1\n",
    "# Usamos la clase positiva (1)\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1]  # Tomamos la clase 1 (ganado)\n",
    "\n",
    "# Summary Plot: Muestra la importancia y la dirección de las variables\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedccd33",
   "metadata": {},
   "source": [
    "#### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el explainer LIME\n",
    "explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train.values,                   # Datos de entrenamiento (para generar muestras)\n",
    "    feature_names=feature_names,      # Nombres de las columnas\n",
    "    class_names=['Lost', 'Won'],      # Etiquetas de clase (0 = Lost, 1 = Won)\n",
    "    mode='classification'             # Tipo de problema\n",
    ")\n",
    "\n",
    "# Elegir una instancia específica para explicar (ej. índice 0)\n",
    "i = 0\n",
    "exp = explainer_lime.explain_instance(\n",
    "    X_test.iloc[i].values,            # Instancia a explicar\n",
    "    best_bst.predict_proba,           # Función de predicción del modelo (probabilidades)\n",
    "    num_features=X_test.shape[1]\n",
    ")\n",
    "\n",
    "# Mostrar la explicación\n",
    "exp.save_to_file('lime_explanation.html')  # Guardar como HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a180d",
   "metadata": {},
   "source": [
    "#### Ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecdd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables continuas verdaderas\n",
    "continuous_features = [\n",
    "    'product_A_sold_in_the_past',\n",
    "    'product_B_sold_in_the_past',\n",
    "    'product_A_recommended',\n",
    "    'product_A',\n",
    "    'product_C',\n",
    "    'product_D',\n",
    "    'cust_hitrate',\n",
    "    'cust_interactions', \n",
    "    'cust_contracts',  \n",
    "    'opp_month', \n",
    "    'opp_old'\n",
    "]\n",
    "\n",
    "# Muestrear 100 observaciones para claridad\n",
    "X_sample = X_test.sample(100, random_state=42)\n",
    "\n",
    "# Generar ICE + PDP para cada variable\n",
    "for feature in continuous_features:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        best_bst,\n",
    "        X_sample,\n",
    "        features=[feature],\n",
    "        kind='both',      # PDP + ICE\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"ICE + PDP for {feature} (XGBoost)\")\n",
    "    ax.set_ylabel(\"Predicted Probability (Won)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bcb74",
   "metadata": {},
   "source": [
    "#### Ceteris Paribus Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables continuas verdaderas\n",
    "continuous_features = [\n",
    "    'product_A_sold_in_the_past',\n",
    "    'product_B_sold_in_the_past',\n",
    "    'product_A_recommended',\n",
    "    'product_A',\n",
    "    'product_C',\n",
    "    'product_D',\n",
    "    'cust_hitrate',\n",
    "    'cust_interactions', \n",
    "    'cust_contracts',  \n",
    "    'opp_month', \n",
    "    'opp_old'\n",
    "]\n",
    "\n",
    "# Muestrear 100 observaciones para claridad\n",
    "X_sample = X_test.sample(100, random_state=42)\n",
    "\n",
    "# Generar ICE + PDP para cada variable\n",
    "for feature in continuous_features:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        best_bst,\n",
    "        X_sample,\n",
    "        features=[feature],\n",
    "        kind='both',      # PDP + ICE\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"ICE + PDP for {feature} (XGBoost)\")\n",
    "    ax.set_ylabel(\"Predicted Probability (Won)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691673b",
   "metadata": {},
   "source": [
    "#### CounterFactual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir X_test a numpy\n",
    "X_test_np = X_test.values\n",
    "instance = X_test_np[0].reshape(1, -1)  # Primera oportunidad\n",
    "\n",
    "# Definir el modelo predictivo (probabilidades)\n",
    "predict_fn = lambda x: best_bst.predict_proba(x)\n",
    "\n",
    "# Configurar el explainer\n",
    "cf = Counterfactual(\n",
    "    predict_fn,\n",
    "    shape=(1,) + X_test_np.shape[1:],\n",
    "    target_class=1,        # Queremos que la predicción sea 1 (Won)\n",
    "    method='genetic',      # No requiere gradientes → funciona con XGBoost\n",
    "    tol=0.01,              # Tolerancia para la probabilidad objetivo\n",
    "    max_iter=500           # Máximo de iteraciones\n",
    ")\n",
    "\n",
    "# Generar contrafactual\n",
    "explanation = cf.explain(instance)\n",
    "\n",
    "# Mostrar resultado\n",
    "if explanation.cf is not None:\n",
    "    print(\"Contrafactual encontrado:\")\n",
    "    cf_instance = explanation.cf['X']\n",
    "    print(\"Valores originales:\", instance[0])\n",
    "    print(\"Valores contrafactuales:\", cf_instance[0])\n",
    "    print(\"Predicción original:\", best_bst.predict_proba(instance)[0, 1])\n",
    "    print(\"Predicción contrafactual:\", best_bst.predict_proba(cf_instance)[0, 1])\n",
    "else:\n",
    "    print(\"No se encontró un contrafactual.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d087c",
   "metadata": {},
   "source": [
    "### Métodos globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el valor absoluto medio por característica\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)  # Promedio sobre todas las instancias\n",
    "\n",
    "# Crear DataFrame para facilitar la visualización\n",
    "feature_names = X_test.columns if hasattr(X_test, 'columns') else [f\"Feature_{i}\" for i in range(X_test.shape[1])]\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'mean_abs_shap': mean_abs_shap\n",
    "}).sort_values('mean_abs_shap', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "bars = plt.barh(importance_df['feature'], importance_df['mean_abs_shap'], color='lightcoral')\n",
    "\n",
    "# Añadir valores numéricos en las barras\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.005, bar.get_y() + bar.get_height()/2, f'{width:.3f}', \n",
    "             ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.xlabel('mean(|SHAP|)')\n",
    "plt.title('Feature Importance - Mean Absolute SHAP Values')\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f2252",
   "metadata": {},
   "source": [
    "#### Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335edf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular importancia\n",
    "perm_imp = permutation_importance(\n",
    "    best_bst, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    n_repeats=5, \n",
    "    random_state=42,\n",
    "    scoring='f1'  # Usa la métrica del reto\n",
    ")\n",
    "\n",
    "# Crear DataFrame\n",
    "perm_imp_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': perm_imp.importances_mean,\n",
    "    'std': perm_imp.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(perm_imp_df['feature'], perm_imp_df['importance'])\n",
    "plt.xlabel('Permutation Importance (Δ F1-score)')\n",
    "plt.title('Global Feature Importance via Permutation')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a133a04",
   "metadata": {},
   "source": [
    "#### Ale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deab497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir función de predicción que acepte modelo y datos\n",
    "def predict_fn(model, X):\n",
    "    return model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Crear el explainer\n",
    "explainer = dx.Explainer(\n",
    "    model=best_bst,\n",
    "    data=X_test,\n",
    "    predict_function=predict_fn  # función que acepta (model, X)\n",
    ")\n",
    "\n",
    "# ALE plot\n",
    "ale_obj = explainer.model_profile(type='accumulated', variables=['cust_interactions'])\n",
    "ale_obj.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "ale_obj = explainer.model_profile(\n",
    "    type='accumulated',\n",
    "    variables=['cust_interactions', 'opp_old', 'product_A_sold_in_the_past']\n",
    ")\n",
    "ale_obj.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
